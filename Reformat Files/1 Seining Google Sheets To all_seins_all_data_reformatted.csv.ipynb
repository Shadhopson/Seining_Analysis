{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan: Reformat to include Date, Time, Weathe & Air Temp, Water Temp, Tide Times, Tide is Moving, DO, PH, Salinity, Turbidity, # of Student Seiners, # of visitors, Instructors/ Seine Staff, Hauls, Common Name, Quantity,  # Brought to Ed Center, Other Info, Notes from seining season,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching to the 2017 version. No other season has all of these columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_recent(df):\n",
    "    init_list = df.columns.values[:14] #get columns that need to have their Nan filled with earlier rows values\n",
    "    curr_vals = df.loc[0][:14]      \n",
    "    for i, row in df.iterrows():\n",
    "        if pd.isnull(df.loc[i,'Date']):  # if the date is null, fill in the pre existing values\n",
    "            df.loc[i] = list(curr_vals) + list(df.loc[i][14:])\n",
    "        else:\n",
    "            curr_vals = df.loc[i][:14]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_recent_2019(df):\n",
    "    init_list = df.columns.values[:19] #get columns that need to have their Nan filled with earlier rows values\n",
    "    curr_vals = df.loc[0][:19]      \n",
    "    for i, row in df.iterrows():\n",
    "        if pd.isnull(df.loc[i,'Date']):  # if the date is null, fill in the pre existing values\n",
    "            df.loc[i] = list(curr_vals) + list(df.loc[i][19:])\n",
    "        else:\n",
    "            curr_vals = df.loc[i][:19]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns(curr_df, match_df):\n",
    "    for col in match_df.columns.values:\n",
    "        if col not in curr_df:\n",
    "            curr_df[col] = \"\"\n",
    "    return curr_df[match_df.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_2008 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=737788186&format=csv'\n",
    "csv_2009 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=1188626592&format=csv'\n",
    "csv_2010 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=1492092969&format=csv'\n",
    "csv_2011 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=1154911519&format=csv'\n",
    "csv_2012 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=1815364461&format=csv'\n",
    "csv_2013 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=1417342758&format=csv'\n",
    "csv_2014 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=1605738199&format=csv'\n",
    "csv_2015 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=0&format=csv'\n",
    "csv_2016 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=1068275557&format=csv'\n",
    "csv_2017 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=126889157&format=csv'\n",
    "csv_2018 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=375464720&format=csv'\n",
    "csv_2019 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=2104825567&format=csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = reformat_recent(pd.read_csv(csv_2017))\n",
    "\n",
    "combined_df['Scientific Name'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving the scientific name column\n",
    "combined_df =  combined_df[list(combined_df.columns.values[:14])+list(combined_df.columns.values[-1:]) + list(combined_df.columns.values[14:-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = pd.read_csv(csv_2018)\n",
    "df_2018.rename(columns= {\"NOTES FROM SEINE:\":\"NOTES FROM SEINEING SEASON:\"})\n",
    "df_2018 = add_columns(df_2018, combined_df)\n",
    "df_2018 = reformat_recent(df_2018)\n",
    "combined_df = pd.concat([combined_df, df_2018], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 =  pd.read_csv(csv_2016)\n",
    "df_2016.rename(columns={\"Weather (exact air temp):\": 'Weather & Air Temp:', \"# student seiners (12+)\": '# student seiners (CLASSES ONLY)',\"# of visitors (Public Seine)\":'# of visitors (Public Seine ONLY)'}, inplace=True)\n",
    "df_2016 = add_columns(df_2016, combined_df)\n",
    "df_2016 = reformat_recent(df_2016)\n",
    "combined_df = pd.concat([df_2016,combined_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015 =  pd.read_csv(csv_2015)\n",
    "df_2015.rename(columns={\"Weather (exact air temp):\": 'Weather & Air Temp:', \"#of Participants\":'# of visitors (Public Seine ONLY)', \"Instructors/Staff:\":\"Instructors/ Seine Staff:\", \"Other info (Dead/Alive)\":\"Other info (Gender, Length, Dead/Alive, other physical description)\"}, inplace=True)\n",
    "df_2015 = add_columns(df_2015, combined_df)\n",
    "df_2015 = reformat_recent(df_2015)\n",
    "combined_df = pd.concat([df_2015,combined_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014 =  pd.read_csv(csv_2014)\n",
    "\n",
    "df_2014.rename(columns={\"Weather (exact air temp):\": 'Weather & Air Temp:', \"#of Participants\":'# of visitors (Public Seine ONLY)', \"Instructors/Staff:\":\"Instructors/ Seine Staff:\", \"Other info (Dead/Alive)\":\"Other info (Gender, Length, Dead/Alive, other physical description)\"}, inplace=True)\n",
    "df_2014 = add_columns(df_2014, combined_df)\n",
    "\n",
    "df_2014 = reformat_recent(df_2014)\n",
    "\n",
    "combined_df = pd.concat([df_2014,combined_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013 =  pd.read_csv(csv_2013)\n",
    "df_2013.columns = list(df_2013.loc[0])\n",
    "df_2013 = df_2013[1:]\n",
    "\n",
    "weatherAndTemp = []\n",
    "for i,val in enumerate(list(df_2013['Weather:'])):\n",
    "    temp_val = list(df_2013[\"Air Temp:\"])[i]\n",
    "    if temp_val == temp_val:\n",
    "        weatherAndTemp.append(val + \" \" + temp_val)\n",
    "    else:\n",
    "        weatherAndTemp.append(val)\n",
    "\n",
    "\n",
    "df_2013['Weather & Air Temp:'] =  weatherAndTemp\n",
    "\n",
    "df_2013.rename(columns={ \"Instructors\":\"Instructors/ Seine Staff:\"}, inplace=True)\n",
    "df_2013 = df_2013.reset_index()\n",
    "df_2013 = add_columns(df_2013, combined_df)\n",
    "\n",
    "\n",
    "df_2013 = reformat_recent(df_2013)\n",
    "combined_df = pd.concat([df_2013,combined_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_2012():\n",
    "\n",
    "    df_2012 = pd.read_csv(csv_2012)\n",
    "    columns = df_2012.columns.values\n",
    "    #Find columns with 2 // as with dates 03/30/15\n",
    "    date_columns = [date for date in columns if date.count('/') == 2 ]\n",
    "    df_list = []\n",
    "    \n",
    "    # for every date make a separate dataframe\n",
    "    for date_col_name in date_columns:\n",
    "        #get all species names and all values for that day\n",
    "        abridged_df = df_2012[['Name of Species', date_col_name]].head(50)\n",
    "        abridged_df['Date']  = date_col_name\n",
    "        #remove all rows where nothing was caught\n",
    "        abridged_df = abridged_df.dropna()\n",
    "        abridged_df.rename(columns={date_col_name: 'Quantity', 'Name of Species': 'Common Name'}, inplace=True)\n",
    "        df_list.append(abridged_df)\n",
    "    #combine all the dataframes into one big one\n",
    "    sein_df_2012 = pd.concat(df_list)\n",
    "    return sein_df_2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2012 = reformat_2012()\n",
    "\n",
    "df_2012 = add_columns(df_2012, combined_df)\n",
    "new_quantities = []\n",
    "for val in list(df_2012['Quantity']):\n",
    "    if type(val) == float:\n",
    "        new_quantities.append(str(int(val)))\n",
    "    else:\n",
    "        new_quantities.append(val)\n",
    "df_2012['Quantity'] = new_quantities\n",
    "\n",
    "combined_df = pd.concat([df_2012,combined_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_2011():\n",
    "    df_2011 = pd.read_csv(csv_2011)            \n",
    "    #set proper column indexes and remove junk rows\n",
    "    df_2011.columns = df_2011.iloc[1]\n",
    "    df_2011.reindex(df_2011.index.drop(1))\n",
    "    df_2011 = df_2011.drop([0,1,36])\n",
    "    #renaming columns to substitute for blank values '######' with approximations\n",
    "    df_2011.columns = ['Name of Species', '5/10/2011', '5/14/2011', '5/20/2011', '5/28/2011',\n",
    "           'Total Number May', '6/11/2011', '6/14/2011', '6/26/2011',\n",
    "           'Total Number June', '7/10/2011', '7/11/2011', '7/12/2011',\n",
    "           '7/13/2011', 'Total Number July', '8/02/2011', '8/9/2011',\n",
    "           '8/10/2011', 'Total Number August', '9/10/2011', '9/20/2011', '9/26/2011',\n",
    "           'Total Number Sept', 'Total Number October']\n",
    "    #remove columns that are just sums of past columns\n",
    "    selected_columns = [col for col in df_2011 if \"Total\" not in col]\n",
    "    df_2011 = df_2011[selected_columns]\n",
    "    df_2011.head()\n",
    "    df_list_2011 = []\n",
    "    for col in df_2011.columns.values:\n",
    "        if col == 'Name of Species':\n",
    "            continue\n",
    "        abridged_df = df_2011[['Name of Species', col]]\n",
    "        abridged_df['Date'] = col#datetime.strptime(col, '%m/%d/%Y' )\n",
    "        abridged_df = abridged_df.dropna()\n",
    "        abridged_df.rename(columns={col: 'Quantity', 'Name of Species': 'Common Name'}, inplace=True)\n",
    "        df_list_2011.append(abridged_df)\n",
    "\n",
    "    sein_df_2011 = pd.concat(df_list_2011)\n",
    "    return sein_df_2011\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shad\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_2011 = reformat_2011()\n",
    "\n",
    "df_2011 = add_columns(df_2011, combined_df)\n",
    "\n",
    "combined_df = pd.concat([df_2011,combined_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_2010():\n",
    "    df_2010 = pd.read_csv(csv_2010)\n",
    "    df_2010 = df_2010.drop([0])\n",
    "    curr_date = df_2010.loc[1]\n",
    "    for i, date in df_2010.iterrows():\n",
    "        if pd.isnull(df_2010.loc[i, 'Unnamed: 0']):\n",
    "            df_2010.loc[i, 'Unnamed: 0'] = curr_date\n",
    "        else:\n",
    "            curr_date = df_2010.loc[i, 'Unnamed: 0']\n",
    "    df_2010 = df_2010.drop([1])\n",
    "    #rename columns\n",
    "    df_2010.rename(columns={\"Unnamed: 0\": \"Date\", \"Seining catch 2010\": \"Common Name\", \"Unnamed: 2\":\"Other info (Gender, Length, Dead/Alive, other physical description)\"}, inplace=True)\n",
    "    df_2010 = df_2010.dropna(subset=['Common Name'])\n",
    "    return df_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2010 = reformat_2010()\n",
    "\n",
    "df_2010 =  add_columns(df_2010, combined_df)\n",
    "\n",
    "combined_df = pd.concat([df_2010,combined_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_2009(): \n",
    "    df_2009 = pd.read_csv(csv_2009)\n",
    "    df_2009 = df_2009.drop([0,1,16])\n",
    "    curr_date = df_2009.loc[2]\n",
    "\n",
    "    for i, date in df_2009.iterrows():\n",
    "        if pd.isnull(df_2009.loc[i, 'Unnamed: 0']):\n",
    "            df_2009.loc[i, 'Unnamed: 0'] = curr_date\n",
    "        else:\n",
    "            curr_date = df_2009.loc[i, 'Unnamed: 0']\n",
    "\n",
    "    df_2009 = df_2009[['Unnamed: 0', 'Seining catch 2009']]\n",
    "    df_2009 = df_2009.dropna()\n",
    "    df_2009.rename(columns={\"Unnamed: 0\": \"Date\", \"Seining catch 2009\": \"Common Name\"}, inplace=True)\n",
    "    return df_2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009 = reformat_2009()\n",
    "\n",
    "df_2009 =  add_columns(df_2009, combined_df)\n",
    "\n",
    "df_2009 = df_2009.drop([2])\n",
    "\n",
    "combined_df = pd.concat([df_2009,combined_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_2008():\n",
    "    df_2008 = pd.read_csv(csv_2008)\n",
    "    df_2008 = df_2008.drop([0,1])\n",
    "    curr_date = df_2008.loc[2]\n",
    "\n",
    "    for i, date in df_2008.iterrows():\n",
    "            if pd.isnull(df_2008.loc[i, 'Unnamed: 0']):\n",
    "                df_2008.loc[i, 'Unnamed: 0'] = curr_date\n",
    "            else:\n",
    "                curr_date = df_2008.loc[i, 'Unnamed: 0']\n",
    "\n",
    "    df_2008 = df_2008.drop([2])\n",
    "\n",
    "    df_2008 = df_2008[['Unnamed: 0', 'Seining catch 2008']]\n",
    "    df_2008 = df_2008.dropna()\n",
    "    #rename columns\n",
    "    df_2008.rename(columns={\"Unnamed: 0\": \"Date\", \"Seining catch 2008\": \"Common Name\"}, inplace=True)\n",
    "    return df_2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2008 =  reformat_2008()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2008 =  add_columns(df_2008, combined_df)\n",
    "combined_df = pd.concat([df_2008,combined_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_2019():\n",
    "    df_2019 = pd.read_csv(csv_2019)\n",
    "    df_2019 = df_2019.rename(columns={'Weather & Air Temp (F):':'Weather & Air Temp:','Water Temp (F):':'Water Temp:','DO (mg/L)':'DO',\n",
    "                      'Salinity (ppt)': 'Salinity','Turbidity (NTU)':'Turbidity'})\n",
    "    df_2019 = reformat_recent_2019(df_2019)\n",
    "    return df_2019\n",
    "df_2019 = reformat_2019()\n",
    "\n",
    "combined_df = pd.concat([combined_df, df_2019], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Quantity'] = combined_df['Quantity'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[combined_df['Common Name'] == combined_df['Common Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('../Created CSVs/all_seins_all_data_reformatted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
