{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brooklyn Bridge Park Conservancy Seining Catch list 2013</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Date</td>\n",
       "      <td>Time</td>\n",
       "      <td>Weather:</td>\n",
       "      <td>Air Temp:</td>\n",
       "      <td>Instructors:</td>\n",
       "      <td>Common Name</td>\n",
       "      <td>Quantity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/4/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blueback herring</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bay anchovy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer flounder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>glass shrimp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Brooklyn Bridge Park Conservancy Seining Catch list 2013 Unnamed: 1  \\\n",
       "0                                               Date             Time   \n",
       "1                                           6/4/2013              NaN   \n",
       "2                                                NaN              NaN   \n",
       "3                                                NaN              NaN   \n",
       "4                                                NaN              NaN   \n",
       "\n",
       "  Unnamed: 2 Unnamed: 3    Unnamed: 4        Unnamed: 5 Unnamed: 6  \n",
       "0   Weather:  Air Temp:  Instructors:       Common Name   Quantity  \n",
       "1        NaN        NaN           NaN  Blueback herring          1  \n",
       "2        NaN        NaN           NaN       Bay anchovy          1  \n",
       "3        NaN        NaN           NaN   Summer flounder          1  \n",
       "4        NaN        NaN           NaN      glass shrimp          1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#google sheets datasets\n",
    "csv_2008 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=737788186&format=csv'\n",
    "csv_2009 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=1188626592&format=csv'\n",
    "csv_2010 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=1492092969&format=csv'\n",
    "csv_2011 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=1154911519&format=csv'\n",
    "csv_2012 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=1815364461&format=csv'\n",
    "csv_2013 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=1417342758&format=csv'\n",
    "csv_2014 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=1605738199&format=csv'\n",
    "csv_2015 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=0&format=csv'\n",
    "csv_2016 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=1068275557&format=csv'\n",
    "csv_2017 = 'https://docs.google.com/spreadsheets/d/1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g/export?gid=126889157&format=csv'\n",
    "\n",
    "#csv datasets\n",
    "#csv_2008 = 'Sein_Data/Seining Data 2008-2017 - 2008 Catch.csv'\n",
    "#csv_2009 = 'Sein_Data/Seining Data 2008-2017 - 2009 Catch.csv'\n",
    "#csv_2010 = 'Sein_Data/Seining Data 2008-2017 - 2010 Catch.csv'\n",
    "#csv_2011 = 'Sein_Data/Seining Data 2008-2017 - 2011 Catch.csv'\n",
    "#csv_2012 = 'Sein_Data/Seining Data 2008-2017 - 2012 Catch.csv'\n",
    "#csv_2013 = 'Sein_Data/Seining Data 2008-2017 - 2013 Catch.csv'\n",
    "#csv_2014 = 'Sein_Data/Seining Data 2008-2017 - 2014 Catch.csv'\n",
    "#csv_2015 = 'Sein_Data/Seining Data 2008-2017 - 2015 Catch.csv'\n",
    "#csv_2016 = 'Sein_Data/Seining Data 2008-2017 - 2016 Catch.csv'\n",
    "#csv_2017 = 'Sein_Data/Seining Data 2008-2017 - 2017 Catch.csv'\n",
    "\n",
    "df_2008 =  pd.read_csv(csv_2013)\n",
    "sheet = '1TH5vctylelJl_yHXJtiAnW48R4dEI-t_E-ObkWZ6-5g'\n",
    "df_2012 = pd.read_csv('https://docs.google.com/spreadsheets/d/' + \n",
    "                   sheet +\n",
    "                   '/export?gid=1815364461&format=csv'\n",
    "                  )\n",
    "df_2008.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reformat_recent(df):\n",
    "    df = df[['Date', 'Common Name', 'Quantity']]\n",
    "    curr_date = df.loc[1,'Date']\n",
    "    for i, date in df.iterrows():\n",
    "        if pd.isnull(df.loc[i, 'Date']):\n",
    "            df.loc[i, 'Date'] = curr_date\n",
    "        else:\n",
    "            df.loc[i, 'Date'] = df.loc[i, 'Date'].split(\" \", 1)[0]\n",
    "            try:\n",
    "                curr_date = datetime.strptime(df.loc[i, 'Date'], '%m/%d/%Y' )\n",
    "            except:\n",
    "                curr_date = datetime.strptime(df.loc[i, 'Date'], '%m/%d/%y' )\n",
    "            df.loc[i, 'Date'] = curr_date\n",
    "    df.rename(columns={\"Common Name\": \"Species\", \"Quantity\": \"Number Caught\"}, inplace=True)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_2017_extra = pd.read_csv('Sein_Data/Seining Data 2008-2017 - 2017 Catch.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_17 =reformat_recent(df_2017_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reformat_2012():\n",
    "\n",
    "    df_2012 = pd.read_csv(csv_2012)\n",
    "    columns = df_2012.columns.values\n",
    "    #Find columns with 2 // as with dates 03/30/15\n",
    "    date_columns = [date for date in columns if date.count('/') == 2 ]\n",
    "    df_list = []\n",
    "    \n",
    "    # for every date make a separate dataframe\n",
    "    for date_col_name in date_columns:\n",
    "        #get all species names and all values for that day\n",
    "        abridged_df = df_2012[['Name of Species', date_col_name]].head(50)\n",
    "        #make column of dates\n",
    "        try:\n",
    "            #print date_col_name\n",
    "            abridged_df['Date'] =  datetime.strptime(date_col_name, '%m/%d/%Y' )\n",
    "        #except:\n",
    "        #    abridged_df['Date'] =  datetime.strptime(date_col_name, '%m/%d/%y' )\n",
    "        except:\n",
    "            try:\n",
    "                abridged_df['Date'] =  datetime.strptime(date_col_name, '%m/%d/`%y' )\n",
    "            except:\n",
    "                abridged_df['Date'] =  datetime.strptime(date_col_name, '%m/%d/%y' )\n",
    "        #remove all rows where nothing was caught\n",
    "        abridged_df = abridged_df.dropna()\n",
    "        abridged_df.rename(columns={date_col_name: 'Number Caught', 'Name of Species': 'Species'}, inplace=True)\n",
    "        df_list.append(abridged_df)\n",
    "    #combine all the dataframes into one big one\n",
    "    sein_df_2012 = pd.concat(df_list)\n",
    "    return sein_df_2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reformat_2011():\n",
    "    df_2011 = pd.read_csv(csv_2011)            \n",
    "    #set proper column indexes and remove junk rows\n",
    "    df_2011.columns = df_2011.iloc[1]\n",
    "    df_2011.reindex(df_2011.index.drop(1))\n",
    "    df_2011 = df_2011.drop([0,1,36])\n",
    "    #renaming columns to substitute for blank values '######' with approximations\n",
    "    df_2011.columns = ['Name of Species', '5/10/2011', '5/14/2011', '5/20/2011', '5/28/2011',\n",
    "           'Total Number May', '6/11/2011', '6/14/2011', '6/26/2011',\n",
    "           'Total Number June', '7/10/2011', '7/11/2011', '7/12/2011',\n",
    "           '7/13/2011', 'Total Number July', '8/02/2011', '8/9/2011',\n",
    "           '8/10/2011', 'Total Number August', '9/10/2011', '9/20/2011', '9/26/2011',\n",
    "           'Total Number Sept', 'Total Number October']\n",
    "    #remove columns that are just sums of past columns\n",
    "    selected_columns = [col for col in df_2011 if \"Total\" not in col]\n",
    "    df_2011 = df_2011[selected_columns]\n",
    "    df_2011.head()\n",
    "    df_list_2011 = []\n",
    "    for col in df_2011.columns.values:\n",
    "        if col == 'Name of Species':\n",
    "            continue\n",
    "        abridged_df = df_2011[['Name of Species', col]]\n",
    "        abridged_df['Date'] = datetime.strptime(col, '%m/%d/%Y' )\n",
    "        abridged_df = abridged_df.dropna()\n",
    "        abridged_df.rename(columns={col: 'Number Caught', 'Name of Species': 'Species'}, inplace=True)\n",
    "        df_list_2011.append(abridged_df)\n",
    "\n",
    "    sein_df_2011 = pd.concat(df_list_2011)\n",
    "    return sein_df_2011\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reformat_2010():\n",
    "    df_2010 = pd.read_csv(csv_2010)\n",
    "    df_2010 = df_2010.drop([0])\n",
    "    curr_date = df_2010.loc[1]\n",
    "    for i, date in df_2010.iterrows():\n",
    "        if pd.isnull(df_2010.loc[i, 'Unnamed: 0']):\n",
    "            df_2010.loc[i, 'Unnamed: 0'] = curr_date\n",
    "        else:\n",
    "            try:\n",
    "                curr_date = datetime.strptime(df_2010.loc[i, 'Unnamed: 0'], '%A, %B %d, %Y' )\n",
    "            except:\n",
    "                date_string = df_2010.loc[i, 'Unnamed: 0'] + \", 2010\"\n",
    "                curr_date = datetime.strptime(date_string, '%A %B %d, %Y' )\n",
    "            df_2010.loc[i, 'Unnamed: 0'] = curr_date\n",
    "    df_2010 = df_2010[['Unnamed: 0', 'Seining catch 2010']]\n",
    "    df_2010 = df_2010.dropna()\n",
    "    df_2010 = df_2010.drop([1])\n",
    "    #rename columns\n",
    "    df_2010.rename(columns={\"Unnamed: 0\": \"Date\", \"Seining catch 2010\": \"Species\"}, inplace=True)\n",
    "    df_2010['Number Caught'] = np.NaN\n",
    "    #datetime_object = datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')\n",
    "    return df_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reformat_2009(): \n",
    "    df_2009 = pd.read_csv(csv_2009)\n",
    "    df_2009 = df_2009.drop([0,1,16])\n",
    "    curr_date = df_2009.loc[2]\n",
    "\n",
    "\n",
    "    for i, date in df_2009.iterrows():\n",
    "        if pd.isnull(df_2009.loc[i, 'Unnamed: 0']):\n",
    "            df_2009.loc[i, 'Unnamed: 0'] = curr_date\n",
    "        else:\n",
    "            try:\n",
    "                curr_date = datetime.strptime(df_2009.loc[i, 'Unnamed: 0'], '%A, %B %d, %Y' )\n",
    "            except:\n",
    "                date_string = df_2009.loc[i, 'Unnamed: 0'] + \", 2009\"\n",
    "                curr_date = datetime.strptime(date_string, '%A %B %d, %Y' )\n",
    "            df_2009.loc[i, 'Unnamed: 0'] = curr_date\n",
    "\n",
    "    df_2009 = df_2009[['Unnamed: 0', 'Seining catch 2009']]\n",
    "    df_2009 = df_2009.dropna()\n",
    "    #rename columns\n",
    "    df_2009.rename(columns={\"Unnamed: 0\": \"Date\", \"Seining catch 2009\": \"Species\"}, inplace=True)\n",
    "    df_2009['Number Caught'] = np.NaN\n",
    "    #datetime_object = datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')\n",
    "    return df_2009\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reformat_2008():\n",
    "    df_2008 = pd.read_csv(csv_2008)\n",
    "    df_2008 = df_2008.drop([0,1])\n",
    "    curr_date = df_2008.loc[2]\n",
    "\n",
    "    for i, date in df_2008.iterrows():\n",
    "            if pd.isnull(df_2008.loc[i, 'Unnamed: 0']):\n",
    "                df_2008.loc[i, 'Unnamed: 0'] = curr_date\n",
    "            else:\n",
    "                try:\n",
    "                    curr_date = datetime.strptime(df_2008.loc[i, 'Unnamed: 0'], '%A, %B %d, %Y' )\n",
    "                except:\n",
    "                    date_string = df_2008.loc[i, 'Unnamed: 0'] + \", 2008\"\n",
    "                    curr_date = datetime.strptime(date_string, '%A %B %d, %Y' )\n",
    "                df_2008.loc[i, 'Unnamed: 0'] = curr_date\n",
    "\n",
    "    df_2008 = df_2008.drop([2])\n",
    "\n",
    "    df_2008 = df_2008[['Unnamed: 0', 'Seining catch 2008']]\n",
    "    df_2008 = df_2008.dropna()\n",
    "    #rename columns\n",
    "    df_2008.rename(columns={\"Unnamed: 0\": \"Date\", \"Seining catch 2008\": \"Species\"}, inplace=True)\n",
    "    df_2008['Number Caught'] = np.NaN\n",
    "    return df_2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sein_df_2008 = reformat_2008()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sein_df_2009 = reformat_2009()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sein_df_2010 = reformat_2010()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "sein_df_2011 = reformat_2011()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sein_df_2012 = reformat_2012()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_2013 = pd.read_csv(csv_2013)\n",
    "\n",
    "df_2013.columns = df_2013.iloc[0]\n",
    "df_2013 = df_2013.drop([0])\n",
    "\n",
    "sein_df_2013 = reformat_recent(df_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_2014 = pd.read_csv(csv_2014)\n",
    "sein_df_2014 = reformat_recent(df_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "sein_df_2015 = reformat_recent(pd.read_csv(csv_2015))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "sein_df_2016 = reformat_recent(pd.read_csv(csv_2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/shad/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "sein_df_2017 = reformat_recent(pd.read_csv(csv_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_seins = pd.concat([sein_df_2008,sein_df_2009,sein_df_2010,sein_df_2011,sein_df_2012, sein_df_2013,sein_df_2014, sein_df_2015, sein_df_2016,sein_df_2017])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_seins = all_seins.dropna(subset=[\"Species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Number Caught</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sea squirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shore shrimp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mantis shrimp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sand shrimp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hermit crab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oyster toadfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>striped bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>northern kingfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>northern pipefish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>striped searobin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlantic silverside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anchovy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blue crab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lady crab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>winter flounder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comb jelly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2008-09-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lion's mane jellyfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-06-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Species caught</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bay anchovy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-06-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>northern pipefish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009-06-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>striped bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009-06-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shore shrimp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009-06-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sand shrimp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009-06-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sea squirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009-06-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blue crab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2009-06-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comb jelly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2009-06-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hydroids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2009-06-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hermit crab,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2009-06-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>snails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2009-06-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two hemigrapsis molts were found on the beach.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>Striped Bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Atlantic Menhaden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>16</td>\n",
       "      <td>Atlantic Silverside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>Silver Perch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter Flounder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>Herring SPP (pre metamorph)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Grass Shrimp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sand Shrimp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Mud Crab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Hermit Crab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Asian Shore Crab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Blue Crab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Mud Snail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Oyster Drill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>Comb Jelly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2017-08-20 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Moon Jelly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2017-09-17 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>YOY Silverside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2017-09-17 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Spotted Whiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2017-09-17 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Striped Bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2017-09-17 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Blue Crab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2017-09-17 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Lady Crab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2017-09-17 00:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>Asian Shore Crab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2017-09-17 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Silverside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2017-09-17 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Grubby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2017-09-17 00:00:00</td>\n",
       "      <td>TMTC</td>\n",
       "      <td>Comb Jelly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2017-09-17 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Shore Shrimp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2017-10-07 00:00:00</td>\n",
       "      <td>TMTC</td>\n",
       "      <td>Comb Jelly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2017-10-07 00:00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>Asian Shore Crab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2017-10-07 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Oyster Drill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2017-10-07 00:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>Mud Snails</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date Number Caught  \\\n",
       "3    2008-09-13 00:00:00           NaN   \n",
       "4    2008-09-13 00:00:00           NaN   \n",
       "5    2008-09-13 00:00:00           NaN   \n",
       "6    2008-09-13 00:00:00           NaN   \n",
       "7    2008-09-13 00:00:00           NaN   \n",
       "8    2008-09-13 00:00:00           NaN   \n",
       "9    2008-09-13 00:00:00           NaN   \n",
       "10   2008-09-13 00:00:00           NaN   \n",
       "11   2008-09-13 00:00:00           NaN   \n",
       "12   2008-09-13 00:00:00           NaN   \n",
       "13   2008-09-13 00:00:00           NaN   \n",
       "14   2008-09-13 00:00:00           NaN   \n",
       "15   2008-09-13 00:00:00           NaN   \n",
       "16   2008-09-13 00:00:00           NaN   \n",
       "17   2008-09-13 00:00:00           NaN   \n",
       "18   2008-09-13 00:00:00           NaN   \n",
       "19   2008-09-13 00:00:00           NaN   \n",
       "2    2009-06-20 00:00:00           NaN   \n",
       "3    2009-06-20 00:00:00           NaN   \n",
       "4    2009-06-20 00:00:00           NaN   \n",
       "5    2009-06-20 00:00:00           NaN   \n",
       "6    2009-06-20 00:00:00           NaN   \n",
       "7    2009-06-20 00:00:00           NaN   \n",
       "8    2009-06-20 00:00:00           NaN   \n",
       "9    2009-06-20 00:00:00           NaN   \n",
       "10   2009-06-20 00:00:00           NaN   \n",
       "11   2009-06-20 00:00:00           NaN   \n",
       "12   2009-06-20 00:00:00           NaN   \n",
       "13   2009-06-20 00:00:00           NaN   \n",
       "14   2009-06-20 00:00:00           NaN   \n",
       "..                   ...           ...   \n",
       "124  2017-08-20 00:00:00             8   \n",
       "125  2017-08-20 00:00:00             1   \n",
       "126  2017-08-20 00:00:00            16   \n",
       "127  2017-08-20 00:00:00             6   \n",
       "128  2017-08-20 00:00:00             1   \n",
       "129  2017-08-20 00:00:00            10   \n",
       "130  2017-08-20 00:00:00             2   \n",
       "131  2017-08-20 00:00:00             1   \n",
       "132  2017-08-20 00:00:00             3   \n",
       "133  2017-08-20 00:00:00             1   \n",
       "134  2017-08-20 00:00:00             4   \n",
       "135  2017-08-20 00:00:00             2   \n",
       "136  2017-08-20 00:00:00             5   \n",
       "137  2017-08-20 00:00:00             2   \n",
       "138  2017-08-20 00:00:00             7   \n",
       "139  2017-08-20 00:00:00             1   \n",
       "140  2017-09-17 00:00:00             6   \n",
       "141  2017-09-17 00:00:00             1   \n",
       "142  2017-09-17 00:00:00             1   \n",
       "143  2017-09-17 00:00:00             5   \n",
       "144  2017-09-17 00:00:00             1   \n",
       "145  2017-09-17 00:00:00            12   \n",
       "146  2017-09-17 00:00:00             1   \n",
       "147  2017-09-17 00:00:00             1   \n",
       "148  2017-09-17 00:00:00          TMTC   \n",
       "149  2017-09-17 00:00:00             2   \n",
       "150  2017-10-07 00:00:00          TMTC   \n",
       "151  2017-10-07 00:00:00            14   \n",
       "152  2017-10-07 00:00:00             4   \n",
       "153  2017-10-07 00:00:00             9   \n",
       "\n",
       "                                            Species  \n",
       "3                                        sea squirt  \n",
       "4                                      shore shrimp  \n",
       "5                                     mantis shrimp  \n",
       "6                                       sand shrimp  \n",
       "7                                       hermit crab  \n",
       "8                                   oyster toadfish  \n",
       "9                                      striped bass  \n",
       "10                                northern kingfish  \n",
       "11                                northern pipefish  \n",
       "12                                 striped searobin  \n",
       "13                              Atlantic silverside  \n",
       "14                                          anchovy  \n",
       "15                                        blue crab  \n",
       "16                                        lady crab  \n",
       "17                                  winter flounder  \n",
       "18                                       comb jelly  \n",
       "19                            lion's mane jellyfish  \n",
       "2                                    Species caught  \n",
       "3                                       bay anchovy  \n",
       "4                                 northern pipefish  \n",
       "5                                      striped bass  \n",
       "6                                      shore shrimp  \n",
       "7                                       sand shrimp  \n",
       "8                                       sea squirts  \n",
       "9                                         blue crab  \n",
       "10                                       comb jelly  \n",
       "11                                         hydroids  \n",
       "12                                     hermit crab,  \n",
       "13                                           snails  \n",
       "14   Two hemigrapsis molts were found on the beach.  \n",
       "..                                              ...  \n",
       "124                                    Striped Bass  \n",
       "125                               Atlantic Menhaden  \n",
       "126                             Atlantic Silverside  \n",
       "127                                    Silver Perch  \n",
       "128                                 Winter Flounder  \n",
       "129                     Herring SPP (pre metamorph)  \n",
       "130                                    Grass Shrimp  \n",
       "131                                     Sand Shrimp  \n",
       "132                                        Mud Crab  \n",
       "133                                     Hermit Crab  \n",
       "134                                Asian Shore Crab  \n",
       "135                                       Blue Crab  \n",
       "136                                       Mud Snail  \n",
       "137                                    Oyster Drill  \n",
       "138                                      Comb Jelly  \n",
       "139                                      Moon Jelly  \n",
       "140                                  YOY Silverside  \n",
       "141                                   Spotted Whiff  \n",
       "142                                    Striped Bass  \n",
       "143                                       Blue Crab  \n",
       "144                                       Lady Crab  \n",
       "145                                Asian Shore Crab  \n",
       "146                                      Silverside  \n",
       "147                                          Grubby  \n",
       "148                                      Comb Jelly  \n",
       "149                                    Shore Shrimp  \n",
       "150                                      Comb Jelly  \n",
       "151                                Asian Shore Crab  \n",
       "152                                    Oyster Drill  \n",
       "153                                      Mud Snails  \n",
       "\n",
       "[924 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_seins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_seins.to_csv('Created CSVs/all_seins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
